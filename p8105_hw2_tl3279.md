p8105_hw2_tl3279
================
Tianqi Li
2024-09-30

## Problem 1

We loaded the dataset, selected the variables, and changed the entry
variable from characters to logical. 1,868 rows × 20 columns.

``` r
NYCsub = read_csv(
  "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
  col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) |>
  janitor::clean_names() |>
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, ada
    ) |>
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

``` r
NYCsub |> 
  select(station_name, line) |> 
  distinct()
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # ℹ 455 more rows

465 unique stations.

``` r
NYCsub |> 
  filter(ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # ℹ 74 more rows

84 are ASA compliant.

``` r
NYCsub |> 
  filter(vending == "NO") |> 
  pull(entry) |> 
  mean()
```

    ## [1] 0.3770492

37.7% of station entrances/exits without vending allow entrance.

``` r
station_A = 
  NYCsub |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A") |> 
  select(station_name, line) |> 
  distinct()
station_A
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # ℹ 50 more rows

60 distinct stations serve the A train

``` r
station_A_ADA = 
  NYCsub |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A", ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
station_A_ADA
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

Of the stations that serve the A train 17 stations are ASA compliant.

## Problem 2

import the Mr. Trash Wheel dataset. Drop the figure, select only columns
with data entrances. Omit rows without dumpster-specific data. Round
sports balls to integers. Add a name to identify that this is Mr. Trash
Wheel. Change the variable type for year so it matches with the other
two datasets.

``` r
Mr_TW = read_excel(
  "data/202409 Trash Wheel Collection Data.xlsx",
  sheet = "Mr. Trash Wheel",
  skip = 1
) |>
  janitor::clean_names() |>
  select(1:14) |>
  filter(!is.na(dumpster)) |>
  mutate(sports_balls = as.integer(round(sports_balls))) |>
  mutate(trash_wheel = "Mr. Trash Wheel") |>
  mutate(year = as.numeric(year))
```

Do the same things with Professor Trash Wheel and Gwynnda.

``` r
Prof_TW = read_excel(
  "data/202409 Trash Wheel Collection Data.xlsx",
  sheet = "Professor Trash Wheel",
  skip = 1) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  mutate(trash_wheel = "Professor Trash Wheel")

Gw_TW = read_excel(
  "data/202409 Trash Wheel Collection Data.xlsx",
  sheet = "Gwynnda Trash Wheel",
  skip = 1) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  mutate(trash_wheel = "Gwynnda Trash Wheel")
```

Bind the datasets.

``` r
TW_tidy = 
  bind_rows(Mr_TW, Prof_TW, Gw_TW) |>
  janitor::clean_names()
TW_tidy
```

    ## # A tibble: 1,033 × 15
    ##    dumpster month  year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71                 13
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91                  8
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7                  16
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52                 14
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76                 18
    ## # ℹ 1,023 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>, trash_wheel <chr>

``` r
cat("The combined dataset contains", nrow(TW_tidy), "observations.")
```

    ## The combined dataset contains 1033 observations.

Key variables include dumpster, year, weight_tons, and so on.

Calculate the total weight of trash collected by Professor Trash Wheel.

``` r
TW_tidy |>
  filter(trash_wheel == "Professor Trash Wheel") |>
  pull(weight_tons) |>
  sum(na.rm = TRUE)
```

    ## [1] 246.74

Professor Trash Wheel collected a total of 246.74 tons of trash

Calculate the total number of cigarette butts collected by Gwynnda in
June of 2022.

``` r
TW_tidy |>
  filter(trash_wheel == "Gwynnda Trash Wheel", month == "June", year == 2022) |>
  pull(cigarette_butts) |>
  sum(na.rm = TRUE)
```

    ## [1] 18120

In June 2022, Gwynnda Trash Wheel collected 18120 cigarette butts.

## Problem 3

Load the datasets. Create a new variable first name for bakers.csv so it
can match with the other two dataset. Remove the “” for one name in
bakes. Replace the full name Joanne to Jo as recorded in other two
datasets.

``` r
bakers = 
  read_csv("data/bakers.csv") |> 
  janitor::clean_names() |> 
  mutate(first_name = word(baker_name, 1))
bakes =
  read_csv("data/bakes.csv") |> 
  janitor::clean_names() |>
  mutate(baker = str_replace_all(baker, '"', ""))
results = 
  read_csv("data/results.csv",
           skip = 2) |> 
  janitor::clean_names() |>
  mutate(baker = str_replace_all(baker, "Joanne", "Jo"))
```

Check for completeness and correctness

``` r
anti_join(results, bakers, by = c("baker" = "first_name", "series"))
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker <chr>, technical <dbl>,
    ## #   result <chr>

All bakers in results can be found in bakers.

``` r
anti_join(bakes, bakers, by = c("baker" = "first_name", "series"))
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker <chr>,
    ## #   signature_bake <chr>, show_stopper <chr>

All bakers in bakes can be found in bakers.

Combine the dataset

``` r
baker_tidy =
  bakers |> 
  left_join(results, by = c("first_name" = "baker", "series")) |>
  left_join(bakes, by = c("first_name" = "baker", "series", "episode"))
```

Rearrange the variables and order of the data

``` r
baker_tidy =
  baker_tidy |>
  select(series, episode, baker_name, baker_age, baker_occupation, hometown,
         signature_bake, show_stopper, technical, result) |>
  arrange(series, episode, baker_name)
baker_tidy
```

    ## # A tibble: 1,136 × 10
    ##    series episode baker_name  baker_age baker_occupation hometown signature_bake
    ##     <dbl>   <dbl> <chr>           <dbl> <chr>            <chr>    <chr>         
    ##  1      1       1 Annetha Mi…        30 Midwife          Essex    "Light Jamaic…
    ##  2      1       1 David Cham…        31 Entrepreneur     Milton … "Chocolate Or…
    ##  3      1       1 Edd Kimber         24 Debt collector … Bradford "Caramel Cinn…
    ##  4      1       1 Jasminder …        45 Assistant Credi… Birming… "Fresh Mango …
    ##  5      1       1 Jonathan S…        25 Research Analyst St Alba… "Carrot Cake …
    ##  6      1       1 Lea Harris         51 Retired          Midloth… "Cranberry an…
    ##  7      1       1 Louise Bri…        44 Police Officer   Manches… "Carrot and O…
    ##  8      1       1 Mark Whith…        48 Bus Driver       South W… "Sticky Marma…
    ##  9      1       1 Miranda Br…        37 Food buyer for … Midhurs… "Triple Layer…
    ## 10      1       1 Ruth Cleme…        31 Retail manager/… Poynton… "Three Tiered…
    ## # ℹ 1,126 more rows
    ## # ℹ 3 more variables: show_stopper <chr>, technical <dbl>, result <chr>

Save the dataset to local file

``` r
write_csv(baker_tidy, "data/baker_tidy.csv")
```

janitor::clean_names() are used to standard column names. Variations of
“Joanne Wheatley” (e.g., “Jo”, “Jo Wheatley”) were standardized across
all datasets to ensure proper merging. The datasets were combined using
left_join(), and columns were reordered for a better view (general
information first, followed by baker details and bake-related data).

The final dataset comprehensive summary of bakers (1,136 X 10 ), such as
the series and episode number, baker information (name, age, occupation,
hometown), and their performance in challenges (signature_bake,
show_stopper, technical).

Create the table

``` r
baker_table =
  baker_tidy |>
  filter(series %in% 5:10, !is.na(result) & result %in% c("STAR BAKER", "WINNER")) |>
  select(series, episode, baker_name, result) |>
  arrange(series, episode)
kable(baker_table, caption = "Star Baker or Winner for Seasons 5 through 10")
```

| series | episode | baker_name           | result     |
|-------:|--------:|:---------------------|:-----------|
|      5 |       1 | Nancy Birtwhistle    | STAR BAKER |
|      5 |       2 | Richard Burr         | STAR BAKER |
|      5 |       3 | Luis Troyano         | STAR BAKER |
|      5 |       4 | Richard Burr         | STAR BAKER |
|      5 |       5 | Kate Henry           | STAR BAKER |
|      5 |       6 | Chetna Makan         | STAR BAKER |
|      5 |       7 | Richard Burr         | STAR BAKER |
|      5 |       8 | Richard Burr         | STAR BAKER |
|      5 |       9 | Richard Burr         | STAR BAKER |
|      5 |      10 | Nancy Birtwhistle    | WINNER     |
|      6 |       1 | Marie Campbell       | STAR BAKER |
|      6 |       2 | Ian Cumming          | STAR BAKER |
|      6 |       3 | Ian Cumming          | STAR BAKER |
|      6 |       4 | Ian Cumming          | STAR BAKER |
|      6 |       5 | Nadiya Hussain       | STAR BAKER |
|      6 |       6 | Mat Riley            | STAR BAKER |
|      6 |       7 | Tamal Ray            | STAR BAKER |
|      6 |       8 | Nadiya Hussain       | STAR BAKER |
|      6 |       9 | Nadiya Hussain       | STAR BAKER |
|      6 |      10 | Nadiya Hussain       | WINNER     |
|      7 |       1 | Jane Beedle          | STAR BAKER |
|      7 |       2 | Candice Brown        | STAR BAKER |
|      7 |       3 | Tom Gilliford        | STAR BAKER |
|      7 |       4 | Benjamina Ebuehi     | STAR BAKER |
|      7 |       5 | Candice Brown        | STAR BAKER |
|      7 |       6 | Tom Gilliford        | STAR BAKER |
|      7 |       7 | Andrew Smyth         | STAR BAKER |
|      7 |       8 | Candice Brown        | STAR BAKER |
|      7 |       9 | Andrew Smyth         | STAR BAKER |
|      7 |      10 | Candice Brown        | WINNER     |
|      8 |       1 | Steven Carter-Bailey | STAR BAKER |
|      8 |       2 | Steven Carter-Bailey | STAR BAKER |
|      8 |       3 | Julia Chernogorova   | STAR BAKER |
|      8 |       4 | Kate Lyon            | STAR BAKER |
|      8 |       5 | Sophie Faldo         | STAR BAKER |
|      8 |       6 | Liam Charles         | STAR BAKER |
|      8 |       7 | Steven Carter-Bailey | STAR BAKER |
|      8 |       8 | Stacey Hart          | STAR BAKER |
|      8 |       9 | Sophie Faldo         | STAR BAKER |
|      8 |      10 | Sophie Faldo         | WINNER     |
|      9 |       1 | Manon Lagrave        | STAR BAKER |
|      9 |       2 | Rahul Mandal         | STAR BAKER |
|      9 |       3 | Rahul Mandal         | STAR BAKER |
|      9 |       4 | Dan Beasley-Harling  | STAR BAKER |
|      9 |       5 | Kim-Joy Hewlett      | STAR BAKER |
|      9 |       6 | Briony Williams      | STAR BAKER |
|      9 |       7 | Kim-Joy Hewlett      | STAR BAKER |
|      9 |       8 | Ruby Bhogal          | STAR BAKER |
|      9 |       9 | Ruby Bhogal          | STAR BAKER |
|      9 |      10 | Rahul Mandal         | WINNER     |
|     10 |       1 | Michelle Evans-Fecci | STAR BAKER |
|     10 |       2 | Alice Fevronia       | STAR BAKER |
|     10 |       3 | Michael Chakraverty  | STAR BAKER |
|     10 |       4 | Steph Blackwell      | STAR BAKER |
|     10 |       5 | Steph Blackwell      | STAR BAKER |
|     10 |       6 | Steph Blackwell      | STAR BAKER |
|     10 |       7 | Henry Bird           | STAR BAKER |
|     10 |       8 | Steph Blackwell      | STAR BAKER |
|     10 |       9 | Alice Fevronia       | STAR BAKER |
|     10 |      10 | David Atherton       | WINNER     |

Star Baker or Winner for Seasons 5 through 10

Predictable Winners: In many seasons, the final winner was predictable.
For example, Richard Burr (Season 5) and Nadiya Hussain (Season 6) were
named “Star Baker” multiple times, making their wins expected.

Surprises: David Atherton (Season 10) was a surprise winner, as he did
not win any “Star Baker” before the final.

Working on the viewwr dataset

``` r
viewers = 
  read_csv("data/viewers.csv") |>
  janitor::clean_names() |>
  pivot_longer(
    cols = starts_with("series_"), 
    names_to = "season", 
    values_to = "viewership") |>
  mutate(season = readr::parse_number(season)) |>
  relocate(season) |>
  arrange(season, episode)
```

Print the first 10 rows

``` r
print(head(viewers, 10))
```

    ## # A tibble: 10 × 3
    ##    season episode viewership
    ##     <dbl>   <dbl>      <dbl>
    ##  1      1       1       2.24
    ##  2      1       2       3   
    ##  3      1       3       3   
    ##  4      1       4       2.6 
    ##  5      1       5       3.03
    ##  6      1       6       2.75
    ##  7      1       7      NA   
    ##  8      1       8      NA   
    ##  9      1       9      NA   
    ## 10      1      10      NA

Calculate the mean

``` r
viewers |>
  filter(season == 1) |>
  pull(viewership) |>
  mean(na.rm = TRUE)
```

    ## [1] 2.77

The mean viewership in Season 1 is 2.77.

``` r
viewers |>
  filter(season == 5) |>
  pull(viewership) |>
  mean(na.rm = TRUE)
```

    ## [1] 10.0393

The mean viewership in Season 5 is 10.0393.
