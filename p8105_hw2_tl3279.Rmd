---
title: "p8105_hw2_tl3279"
author: "Tianqi Li"
date: "2024-09-30"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
library(dplyr)
library(knitr)
```

## Problem 1
We loaded the dataset, selected the variables, and changed the entry variable from characters to logical. 1,868 rows Ã— 20 columns.
```{r}
NYCsub = read_csv(
  "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
  col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) |>
  janitor::clean_names() |>
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, ada
    ) |>
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

```{r}
NYCsub |> 
  select(station_name, line) |> 
  distinct()
```
465 unique stations.

```{r}
NYCsub |> 
  filter(ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```
84 are ASA compliant.

```{r}
NYCsub |> 
  filter(vending == "NO") |> 
  pull(entry) |> 
  mean()
```
37.7% of station entrances/exits without vending allow entrance.

```{r}
station_A = 
  NYCsub |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A") |> 
  select(station_name, line) |> 
  distinct()
station_A
```
60 distinct stations serve the A train

```{r}
station_A_ADA = 
  NYCsub |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A", ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
station_A_ADA
```
Of the stations that serve the A train 17 stations are ASA compliant.

## Problem 2

import the Mr. Trash Wheel dataset. Drop the figure, select only columns with 
data entrances. Omit rows without dumpster-specific data. Round sports balls 
to integers. Add a name to identify that this is Mr. Trash Wheel. Change the 
variable type for year so it matches with the other two datasets.
```{r message = FALSE}
Mr_TW = read_excel(
  "data/202409 Trash Wheel Collection Data.xlsx",
  sheet = "Mr. Trash Wheel",
  skip = 1
) |>
  janitor::clean_names() |>
  select(1:14) |>
  filter(!is.na(dumpster)) |>
  mutate(sports_balls = as.integer(round(sports_balls))) |>
  mutate(trash_wheel = "Mr. Trash Wheel") |>
  mutate(year = as.numeric(year))
```

Do the same things with Professor Trash Wheel and Gwynnda.
```{r}
Prof_TW = read_excel(
  "data/202409 Trash Wheel Collection Data.xlsx",
  sheet = "Professor Trash Wheel",
  skip = 1) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  mutate(trash_wheel = "Professor Trash Wheel")

Gw_TW = read_excel(
  "data/202409 Trash Wheel Collection Data.xlsx",
  sheet = "Gwynnda Trash Wheel",
  skip = 1) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  mutate(trash_wheel = "Gwynnda Trash Wheel")
```

Bind the datasets.

```{r}
TW_tidy = 
  bind_rows(Mr_TW, Prof_TW, Gw_TW) |>
  janitor::clean_names()
TW_tidy
cat("The combined dataset contains", nrow(TW_tidy), "observations.")
```

Key variables include dumpster, year, weight_tons, and so on. 

Calculate the total weight of trash collected by Professor Trash Wheel.
```{r}
TW_tidy |>
  filter(trash_wheel == "Professor Trash Wheel") |>
  pull(weight_tons) |>
  sum(na.rm = TRUE)
```
Professor Trash Wheel collected a total of 246.74 tons of trash

Calculate the total number of cigarette butts collected by Gwynnda in June of 2022.

```{r}
TW_tidy |>
  filter(trash_wheel == "Gwynnda Trash Wheel", month == "June", year == 2022) |>
  pull(cigarette_butts) |>
  sum(na.rm = TRUE)
```
In June 2022, Gwynnda Trash Wheel collected 18120 cigarette butts.

## Problem 3

Load the datasets. Create a new variable first name for bakers.csv so it can 
match with the other two dataset. Remove the "" for one name in bakes. Replace 
the full name Joanne to Jo as recorded in other two datasets.
```{r message = FALSE}
bakers = 
  read_csv("data/bakers.csv") |> 
  janitor::clean_names() |> 
  mutate(first_name = word(baker_name, 1))
bakes =
  read_csv("data/bakes.csv") |> 
  janitor::clean_names() |>
  mutate(baker = str_replace_all(baker, '"', ""))
results = 
  read_csv("data/results.csv",
           skip = 2) |> 
  janitor::clean_names() |>
  mutate(baker = str_replace_all(baker, "Joanne", "Jo"))
```

Check for completeness and correctness
```{r}
anti_join(results, bakers, by = c("baker" = "first_name", "series"))
```
All bakers in results can be found in bakers.

```{r}
anti_join(bakes, bakers, by = c("baker" = "first_name", "series"))
```
All bakers in bakes can be found in bakers.

Combine the dataset
```{r}
baker_tidy =
  bakers |> 
  left_join(results, by = c("first_name" = "baker", "series")) |>
  left_join(bakes, by = c("first_name" = "baker", "series", "episode"))
```

Rearrange the variables and order of the data 
```{r}
baker_tidy =
  baker_tidy |>
  select(series, episode, baker_name, baker_age, baker_occupation, hometown,
         signature_bake, show_stopper, technical, result) |>
  arrange(series, episode, baker_name)
baker_tidy
```

Save the dataset to local file
```{r}
write_csv(baker_tidy, "data/baker_tidy.csv")
```

janitor::clean_names() are used to standard column names. Variations of 
"Joanne Wheatley" (e.g., "Jo", "Jo Wheatley") were standardized across all 
datasets to ensure proper merging. The datasets were combined using left_join(),
and columns were reordered for a better view (general information first, 
followed by baker details and bake-related data). 

The final dataset comprehensive summary of bakers (1,136 X 10 ), such as the 
series and episode number, baker information (name, age, occupation, hometown), 
and their performance in challenges (signature_bake, show_stopper, technical). 

Create the table
```{r}
baker_table =
  baker_tidy |>
  filter(series %in% 5:10, !is.na(result) & result %in% c("STAR BAKER", "WINNER")) |>
  select(series, episode, baker_name, result) |>
  arrange(series, episode)
kable(baker_table, caption = "Star Baker or Winner for Seasons 5 through 10")
```
Predictable Winners: 
In many seasons, the final winner was predictable. For example, Richard Burr 
(Season 5) and Nadiya Hussain (Season 6) were named "Star Baker" multiple times,
making their wins expected.

Surprises: 
David Atherton (Season 10) was a surprise winner, as he did not win any "Star 
Baker" before the final. 

Working on the viewwr dataset
```{r message = FALSE}
viewers = 
  read_csv("data/viewers.csv") |>
  janitor::clean_names() |>
  pivot_longer(
    cols = starts_with("series_"), 
    names_to = "season", 
    values_to = "viewership") |>
  mutate(season = readr::parse_number(season))
```

Print the first 10 rows
```{r}
print(head(viewers, 10))
```

Calculate the mean
```{r}
viewers |>
  filter(season == 1) |>
  pull(viewership) |>
  mean(na.rm = TRUE)
```
The mean viewership in Season 1 is 2.77.

```{r}
viewers |>
  filter(season == 5) |>
  pull(viewership) |>
  mean(na.rm = TRUE)
```
The mean viewership in Season 5 is 10.0393.
